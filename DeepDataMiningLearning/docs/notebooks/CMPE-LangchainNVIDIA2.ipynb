{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyNkNXB8swVXhf3TIKO7UpaO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# LLM Tutorial: Langchain Agent\n","\n","![Status](https://img.shields.io/static/v1.svg?label=Status&message=Finished&color=green)\n","\n","**Filled notebook:**\n","[![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/lkk688/DeepDataMiningLearning/blob/master/docs/notebooks/CMPE-pytorch10-2024Fall_huggingfaceimage.ipynb)\n","[![Open filled In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lkk688/DeepDataMiningLearning/blob/master/docs/notebooks/CMPE-pytorch10-2024Fall_huggingfaceimage.ipynb)       \n","**Author:** Kaikai Liu"],"metadata":{"id":"oB4jrJaT-mr3"}},{"cell_type":"markdown","metadata":{"id":"AHBD6HDpFPfB"},"source":["## Install Pytorch"]},{"cell_type":"markdown","source":["Pytorch is already installed in Colab. If you are installing the pytorch in your local machine, follow the tutorials here: from https://pytorch.org/get-started/locally/. You can check our pytorch installation tutorials for Mac/Windows/Linux/HPC here: https://deepdatamininglearning.readthedocs.io/"],"metadata":{"id":"Be7eF0nZ-dw9"}},{"cell_type":"markdown","source":["Click \"Connect\" to connect to a Colab VM instance. In Runtime->Change Runtime type to select CPU/TPU/GPU."],"metadata":{"id":"2lUmdFDa-zHE"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dt1XGOd-sNDh","executionInfo":{"status":"ok","timestamp":1725296417622,"user_tz":420,"elapsed":225,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"eeb85d2d-6ac9-4e2c-8780-aa31079774c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep  2 17:00:17 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla P100-PCIE-12GB           Off |   00000000:3B:00.0 Off |                    0 |\n","| N/A   32C    P0             26W /  250W |       5MiB /  12288MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"1vyDuiPkFTd5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724700840044,"user_tz":420,"elapsed":23008,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"1b0d7f6b-87a9-4d0f-d23a-9796ad669471"},"source":["!pip3 install torch torchvision"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n","  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"markdown","source":["If the installed version of PyTorch is lower than required, uninstall it and reinstall again by running the following commands:\n","\n","!pip3 uninstall --yes torch torchaudio torchvision torchtext torchdata\n","!pip3 install torch torchaudio torchvision torchtext torchdata"],"metadata":{"id":"8TRnM7K8mGZa"}},{"cell_type":"markdown","source":["---\n","\n","🚨 _Note: the above `pip install` is formatted for Jupyter notebooks. If running elsewhere you may need to drop the `!`._\n","\n","---"],"metadata":{"id":"_o7K-fhnFRQd"}},{"cell_type":"markdown","source":["## Check PyTorch Environment\n","\n","Pytorch is very similar to the `numpy` package. Let's start with importing PyTorch. The package is called `torch`, based on its original framework [Torch](http://torch.ch/). As a first step, we can check its version:"],"metadata":{"id":"ogRnp8eU_kFv"}},{"cell_type":"markdown","source":["Start a local colab container: `docker run --gpus=all -p 127.0.0.1:9000:8080 us-docker.pkg.dev/colab-images/public/runtime`, copy the link output from the terminal. In Colab, select connect to local runtime and paste the link: http://127.0.0.1:9000/?token=cf72df5a62ed764fd3bce315a542cade27d7984365045cc2"],"metadata":{"id":"oIs66cD11JGU"}},{"cell_type":"code","source":["!python -V"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47lGOtCC_pCH","executionInfo":{"status":"ok","timestamp":1725135494380,"user_tz":420,"elapsed":128,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"89d2f51a-e6bf-4f7d-d0d4-288d179fb53e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}]},{"cell_type":"code","source":["!nvidia-smi #check GPU"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XCVSzRy_qN2","executionInfo":{"status":"ok","timestamp":1725135495706,"user_tz":420,"elapsed":220,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"6c2c5c6c-3ee2-4a81-da9b-6d84c9d4aeb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Aug 31 20:18:15 2024       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla P100-PCIE-12GB           Off |   00000000:3B:00.0 Off |                    0 |\n","| N/A   32C    P0             26W /  250W |       5MiB /  12288MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","+-----------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["import torch\n","print(\"Using torch\", torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"85fSPXNq_xwC","executionInfo":{"status":"ok","timestamp":1725135502234,"user_tz":420,"elapsed":2775,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"f5b709bc-3954-4688-a9d3-74ede44aa062"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using torch 2.3.0+cu121\n"]}]},{"cell_type":"code","source":["x = torch.rand(5, 3)\n","print(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4cdmbms_3bm","executionInfo":{"status":"ok","timestamp":1724700703905,"user_tz":420,"elapsed":9,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"75ea21ba-a1c4-470a-f0ea-2b28c37023d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.4722, 0.1678, 0.9813],\n","        [0.6751, 0.5239, 0.5018],\n","        [0.0766, 0.7491, 0.2419],\n","        [0.8492, 0.8048, 0.9454],\n","        [0.8544, 0.7565, 0.1705]])\n"]}]},{"cell_type":"code","source":["import torchvision\n","print(torchvision.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LCTuzlb_5ed","executionInfo":{"status":"ok","timestamp":1725135504635,"user_tz":420,"elapsed":2256,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"444e954b-675f-4301-adda-d151fdfd7f8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.18.0+cu121\n"]}]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    device = torch.device('cuda')  # CUDA GPU\n","elif torch.backends.mps.is_available():\n","    device = torch.device('mps') #Apple GPU\n","else:\n","    device = torch.device(\"cpu\")"],"metadata":{"id":"n2x-qnCK_OdY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Using device:', device)\n","#Additional Info when using cuda\n","if device.type == 'cuda':\n","    print(\"Device name: \", torch.cuda.get_device_name(0))\n","    print(\"Device properties:\", torch.cuda.get_device_properties(0))\n","    print('Memory Usage:')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LceVUVNYACu5","executionInfo":{"status":"ok","timestamp":1725135505395,"user_tz":420,"elapsed":37,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"a27c2a58-937a-46d9-f2a5-96268b1496c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","Device name:  Tesla P100-PCIE-12GB\n","Device properties: _CudaDeviceProperties(name='Tesla P100-PCIE-12GB', major=6, minor=0, total_memory=12186MB, multi_processor_count=56)\n","Memory Usage:\n","Allocated: 0.0 GB\n","Cached:    0.0 GB\n"]}]},{"cell_type":"code","source":["torch.cuda.device_count()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVEeWwCUAGKj","executionInfo":{"status":"ok","timestamp":1724700712185,"user_tz":420,"elapsed":7,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"62eba265-fb64-4a91-8983-69a74ff563bf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["torch.version.cuda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"VZPb2lftAIfb","executionInfo":{"status":"ok","timestamp":1724700714543,"user_tz":420,"elapsed":4,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"624ab881-c3e9-4e5b-a0b1-dabdee74e33a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'12.1'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!nvcc -V"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4y3VuCzxALrE","executionInfo":{"status":"ok","timestamp":1724700802026,"user_tz":420,"elapsed":104,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"ca9a3944-5338-448d-c41b-6c56993deac8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2023 NVIDIA Corporation\n","Built on Tue_Aug_15_22:02:13_PDT_2023\n","Cuda compilation tools, release 12.2, V12.2.140\n","Build cuda_12.2.r12.2/compiler.33191640_0\n"]}]},{"cell_type":"code","source":["torch.backends.cudnn.version()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDna707VAOes","executionInfo":{"status":"ok","timestamp":1724700800057,"user_tz":420,"elapsed":7,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"c2cfb452-164f-4f16-c0c5-cd9f79835e62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8906"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["!echo $LD_LIBRARY_PATH"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ybCKHxPzARMn","executionInfo":{"status":"ok","timestamp":1724700798101,"user_tz":420,"elapsed":96,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"f619622a-b7e6-4755-eab3-983633c67a57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n"]}]},{"cell_type":"markdown","source":["As in every machine learning framework, PyTorch provides functions that are stochastic like generating random numbers. However, a very good practice is to setup your code to be reproducible with the exact same random numbers. This is why we set a seed below."],"metadata":{"id":"TfITcdKBAVYV"}},{"cell_type":"code","source":["torch.manual_seed(42) # Setting the seed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsNtDPlbAUZM","executionInfo":{"status":"ok","timestamp":1723322170964,"user_tz":420,"elapsed":368,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"d15dd192-f4eb-48b3-ba61-80dfbf037f30"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x78f127be8130>"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Agent and Langgraph\n","\n","By themselves, language models can't take actions - they just output text. A big use case for LangChain is creating agents. Agents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs to pass them. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish."],"metadata":{"id":"RJjZdRmUyjyy"}},{"cell_type":"markdown","source":["\n","\n","https://github.com/langchain-ai/langgraph\n","\n","LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. Compared to other LLM frameworks, it offers these core benefits: cycles, controllability, and persistence. LangGraph allows you to define flows that involve cycles, essential for most agentic architectures, differentiating it from DAG-based solutions. As a very low-level framework, it provides fine-grained control over both the flow and state of your application, crucial for creating reliable agents. Additionally, LangGraph includes built-in persistence, enabling advanced human-in-the-loop and memory features."],"metadata":{"id":"Bb10txqPVD2h"}},{"cell_type":"code","source":["! pip install langchain langchain_community langchain_chroma"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8QMfYtgv9SUd","executionInfo":{"status":"ok","timestamp":1726068520304,"user_tz":420,"elapsed":49723,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"c8698317-d6e9-4026-daa1-d79bb28b3884"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain_community\n","  Downloading langchain_community-0.2.16-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain_chroma\n","  Downloading langchain_chroma-0.1.3-py3-none-any.whl (10 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.3.0,>=0.2.38 (from langchain)\n","  Downloading langchain_core-0.2.39-py3-none-any.whl (396 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.6/396.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n","  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.117-py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain_chroma)\n","  Downloading chromadb-0.5.3-py3-none-any.whl (559 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi<1,>=0.95.2 (from langchain_chroma)\n","  Downloading fastapi-0.114.1-py3-none-any.whl (94 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.1)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading posthog-3.6.5-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.12.2)\n","Collecting onnxruntime>=1.14.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.19.1)\n","Collecting pypika>=0.48.9 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.66.4)\n","Collecting overrides>=7.3.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (6.4.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.64.1)\n","Collecting bcrypt>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.12.3)\n","Collecting kubernetes>=28.1.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson>=3.9.12 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx>=0.27.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain_chroma)\n","  Downloading starlette-0.38.5-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.38->langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.1.0)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.0.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.7.1)\n","Collecting httpcore==1.* (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n","Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.13.0)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.0.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.63.2)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n","Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n","Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (67.7.2)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.14.1)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.23.4)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (13.7.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.2.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2023.6.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.19.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (2.16.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.1.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain_chroma) (0.6.0)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53726 sha256=311fa1e92cbcb6c8f6b5ec3a59018239ad905d5ee1ec841247e0e6389d72674e\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, httpcore, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langsmith, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, chromadb, langchain_chroma, langchain, langchain_community\n","Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.3 chromadb-0.5.3 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 fastapi-0.114.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.2 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-0.2.16 langchain-core-0.2.39 langchain-text-splitters-0.2.4 langchain_chroma-0.1.3 langchain_community-0.2.16 langsmith-0.1.117 marshmallow-3.22.0 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 overrides-7.7.0 posthog-3.6.5 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.38.5 typing-inspect-0.9.0 uvicorn-0.30.6 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.0.1\n"]}]},{"cell_type":"code","source":["!pip install -U langgraph"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sAN4o3Ad7hCI","executionInfo":{"status":"ok","timestamp":1726068531885,"user_tz":420,"elapsed":11572,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"d1866bd4-95d8-48b4-b851-f6a1d9abf668"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langgraph\n","  Downloading langgraph-0.2.19-py3-none-any.whl (97 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.1/97.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: langchain-core<0.4,>=0.2.38 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.2.39)\n","Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\n","  Downloading langgraph_checkpoint-1.0.9-py3-none-any.whl (15 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.38->langgraph) (6.0.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.38->langgraph) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.38->langgraph) (0.1.117)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.38->langgraph) (24.1)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.38->langgraph) (2.8.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.38->langgraph) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.38->langgraph) (4.12.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.38->langgraph) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (3.10.7)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (2.31.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.4,>=0.2.38->langgraph) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.4,>=0.2.38->langgraph) (2.20.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (2024.7.4)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (2.0.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.2.38->langgraph) (1.2.1)\n","Installing collected packages: langgraph-checkpoint, langgraph\n","Successfully installed langgraph-0.2.19 langgraph-checkpoint-1.0.9\n"]}]},{"cell_type":"code","source":["!pip install -qU langchain-nvidia-ai-endpoints"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7z02kQnE9PlF","executionInfo":{"status":"ok","timestamp":1726068550331,"user_tz":420,"elapsed":13617,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"b7c623fc-ec74-45b9-9e27-e82d32e40dd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","source":["One of the central concepts of LangGraph is state. Each graph execution creates a state that is passed between nodes in the graph as they execute, and each node updates this internal state with its return value after it executes. The way that the graph updates its internal state is defined by either the type of graph chosen or a custom function."],"metadata":{"id":"VqIE20YF7oDu"}},{"cell_type":"markdown","source":["We'll first create a simple chatbot using LangGraph. This chatbot will respond directly to user messages. Start by creating a StateGraph. A StateGraph object defines the structure of our chatbot as a \"state machine\". We'll add nodes to represent the llm and functions our chatbot can call and edges to specify how the bot should transition between these functions."],"metadata":{"id":"AjExMrh98ADV"}},{"cell_type":"code","source":["from typing import Annotated\n","\n","from typing_extensions import TypedDict\n","\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.graph.message import add_messages\n","\n","#The State consists of the schema of the graph as well as reducer functions which specify how to apply updates to the state.\n","#our example State is a TypedDict with a single key: messages.\n","#The messages key is annotated with the add_messages reducer function, which tells LangGraph to append new messages to the existing list,\n","#rather than overwriting it. State keys without an annotation will be overwritten by each update, storing the most recent value.\n","class State(TypedDict):\n","    # Messages have the type \"list\". The `add_messages` function\n","    # in the annotation defines how this state key should be updated\n","    # (in this case, it appends messages to the list, rather than overwriting them)\n","    messages: Annotated[list, add_messages]\n","\n","\n","graph_builder = StateGraph(State)"],"metadata":{"id":"IUJErDCI8SYp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://langchain-ai.github.io/langgraph/reference/graphs/?h=add+messages#add_messages\n","\n","Every node we define will receive the current State as input and return a value that updates that state.\n","\n","Messages will be appended to the current list, rather than directly overwritten. This is communicated via the prebuilt add_messages function in the Annotated syntax."],"metadata":{"id":"BgCHT8Ka8vO4"}},{"cell_type":"markdown","source":["Next, add a \"chatbot\" node. Nodes represent units of work. They are typically regular python functions."],"metadata":{"id":"riBf2gcV9MRd"}},{"cell_type":"code","source":["import getpass\n","import os\n","\n","if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n","    nvidia_api_key = getpass.getpass(\"Enter your NVIDIA API key: \")\n","    assert nvidia_api_key.startswith(\"nvapi-\"), f\"{nvidia_api_key[:5]}... is not a valid key\"\n","    os.environ[\"NVIDIA_API_KEY\"] = nvidia_api_key"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m596nLbp9aik","executionInfo":{"status":"ok","timestamp":1726068605032,"user_tz":420,"elapsed":11315,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"f750e1bd-efb3-4d80-b0fe-307e1cdbfb13"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your NVIDIA API key: ··········\n"]}]},{"cell_type":"code","source":["from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","\n","# Uncomment the below code to list the availabe models\n","# ChatNVIDIA.get_available_models()\n","\n","\n","llm = ChatNVIDIA(\n","  model=\"meta/llama-3.1-8b-instruct\",\n","  api_key=os.environ[\"NVIDIA_API_KEY\"],\n","  temperature=0.2,\n","  top_p=0.7,\n","  max_tokens=1024,\n",")"],"metadata":{"id":"Se0KWXRT9d4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#the chatbot node function takes the current State as input and returns a dictionary containing an updated messages list under the key \"messages\".\n","#This is the basic pattern for all LangGraph node functions.\n","def chatbot(state: State):\n","    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n","\n","\n","# The first argument is the unique node name\n","# The second argument is the function or object that will be called whenever\n","# the node is used.\n","graph_builder.add_node(\"chatbot\", chatbot)"],"metadata":{"id":"z21w8RQZ9hxV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The add_messages function in our State will append the llm's response messages to whatever messages are already in the state.\n","\n","Next, add an entry point. This tells our graph where to start its work each time we run it."],"metadata":{"id":"51zp4dQz9sD-"}},{"cell_type":"code","source":["graph_builder.add_edge(START, \"chatbot\")"],"metadata":{"id":"v_ZX08Zt9wFG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Similarly, set a finish point. This instructs the graph \"any time this node is run, you can exit.\""],"metadata":{"id":"vxI5_nBc9x_h"}},{"cell_type":"code","source":["graph_builder.add_edge(\"chatbot\", END)"],"metadata":{"id":"eshBjt2D90BB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, we'll want to be able to run our graph. To do so, call \"compile()\" on the graph builder. This creates a \"CompiledGraph\" we can use invoke on our state."],"metadata":{"id":"YPoYnZ8I92Yf"}},{"cell_type":"code","source":["graph = graph_builder.compile()"],"metadata":{"id":"FLXucuqn93z1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can visualize the graph using the get_graph method and one of the \"draw\" methods, like draw_ascii or draw_png. The draw methods each require additional dependencies."],"metadata":{"id":"O08yRkGi96hF"}},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","try:\n","    display(Image(graph.get_graph().draw_mermaid_png()))\n","except Exception:\n","    # This requires some extra dependencies and is optional\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"so_sKb6i97rw","executionInfo":{"status":"ok","timestamp":1726068631327,"user_tz":420,"elapsed":311,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"6c1454b0-908f-4e34-c1e7-f94bbe7e5e0f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/jpeg":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"markdown","source":["You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\"."],"metadata":{"id":"meQoS9Cu9_W0"}},{"cell_type":"code","source":["while True:\n","    user_input = input(\"User: \")\n","    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n","        print(\"Goodbye!\")\n","        break\n","    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n","        for value in event.values():\n","            print(\"Assistant:\", value[\"messages\"][-1].content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xucynqyK-Aij","executionInfo":{"status":"ok","timestamp":1726068788226,"user_tz":420,"elapsed":136607,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"288e6bd8-6e6c-4bd0-ce7f-dff0b7dfe9f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["User: Hello\n","Assistant: Hello! How can I assist you today?\n","User: What's the wildfire in California?\n","Assistant: You're likely referring to the ongoing wildfires in California. Unfortunately, California has been experiencing a series of devastating wildfires in recent years, and it's difficult to pinpoint a single wildfire without more specific information. However, I can provide you with some general information about the current wildfire situation in California.\n","\n","**Current Wildfires:**\n","\n","As of my knowledge cutoff, there are several active wildfires burning across California. Some of the most notable ones include:\n","\n","1. **The Dixie Fire:** This is one of the largest wildfires in California's history, burning over 963,000 acres in Plumas, Butte, Lassen, and Shasta counties.\n","2. **The Caldor Fire:** This fire has burned over 219,000 acres in El Dorado and Amador counties, forcing evacuations and closures in the Sierra Nevada foothills.\n","3. **The Monument Fire:** This fire has burned over 55,000 acres in Trinity and Shasta counties, prompting evacuations and road closures.\n","\n","**Causes and Conditions:**\n","\n","Wildfires in California are often caused by a combination of factors, including:\n","\n","1. **Dry conditions:** California's dry climate, particularly during the summer and fall months, creates an environment conducive to wildfires.\n","2. **High winds:** Gusty winds can spread embers and fuel the growth of wildfires.\n","3. **Human activity:** Accidental ignition from human activity, such as arson or unattended campfires, can also contribute to wildfires.\n","4. **Climate change:** Rising temperatures and changing precipitation patterns due to climate change are creating conditions that are more favorable to wildfires.\n","\n","**Response and Precautions:**\n","\n","To combat wildfires, California's fire agencies, including Cal Fire and the US Forest Service, are working together to:\n","\n","1. **Contain and extinguish fires:** Firefighters are using a range of tactics, including air support, ground crews, and prescribed burns, to contain and extinguish wildfires.\n","2. **Evacuate communities:** Authorities are evacuating communities in the path of the fires to ensure public safety.\n","3. **Implement burn bans:** Local authorities are enforcing burn bans to prevent new fires from starting.\n","4. **Monitor weather conditions:** Firefighters are closely monitoring weather conditions to anticipate and prepare for potential fire spread.\n","\n","**Precautions for the Public:**\n","\n","If you're in California or planning to visit, it's essential to take precautions to stay safe:\n","\n","1. **Monitor local news and fire updates:** Stay informed about the latest fire information and any evacuation orders.\n","2. **Follow evacuation orders:** If ordered to evacuate, do so promptly and follow the recommended evacuation route.\n","3. **Be prepared:** Keep essential items, such as a go-bag, in case of an emergency.\n","4. **Be cautious with fire:** Avoid using fire in areas with high fire danger, and ensure that any outdoor fires are fully extinguished before leaving them unattended.\n","\n","Please note that this information is subject to change, and I recommend checking with local authorities and news sources for the most up-to-date information on wildfires in California.\n","User: Thanks\n","Assistant: You're welcome. Is there something specific you needed help with or would you like to chat about something?\n","User: No\n","Assistant: It seems like you might have started to say something, but it got cut off. Would you like to start again or is there something specific you'd like to talk about? I'm here to listen!\n","User: No, I am leaving now\n","Assistant: It seems like our conversation just started. If you're leaving, I won't be able to respond to any further messages. If you're sure you're ready to go, I'll say goodbye. If you're just taking a break, feel free to come back whenever you're ready to chat.\n","User: quit\n","Goodbye!\n"]}]},{"cell_type":"markdown","source":["This bot can engage in basic conversation by taking user input and generating responses using an LLM. However, you may have noticed that the bot's knowledge is limited to what's in its training data."],"metadata":{"id":"EcPmYJGNuJNP"}},{"cell_type":"markdown","source":["### Add Web Search"],"metadata":{"id":"7C0QJGmGACU7"}},{"cell_type":"markdown","source":["To handle queries our chatbot can't answer \"from memory\", we'll integrate a web search tool. Our bot can use this tool to find relevant information and provide better responses."],"metadata":{"id":"V_nPfHQi-KqM"}},{"cell_type":"markdown","source":["https://python.langchain.com/v0.2/docs/integrations/tools/tavily_search/\n","Tavily's Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed."],"metadata":{"id":"VlL7Khxb_PYh"}},{"cell_type":"markdown","source":["https://tavily.com/, https://app.tavily.com/home (signin via google account)"],"metadata":{"id":"Gz7ymXvw_lbu"}},{"cell_type":"code","source":["%pip install -qU \"langchain-community>=0.2.11\" tavily-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T7MKSOs__UGZ","executionInfo":{"status":"ok","timestamp":1726068907853,"user_tz":420,"elapsed":11953,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"2348e828-d560-4bc7-fb58-1508d3bbe3ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","if not os.environ.get(\"TAVILY_API_KEY\"):\n","    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key:\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fn5oA7YB_W9T","executionInfo":{"status":"ok","timestamp":1726068914715,"user_tz":420,"elapsed":2056,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"1977fb1d-3bd5-444e-e99f-6bdeac36fbc6"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Tavily API key:\n","··········\n"]}]},{"cell_type":"markdown","source":["instantiate an instance of the Tavily search tools"],"metadata":{"id":"0nhB0hou_Tjd"}},{"cell_type":"code","source":["from langchain_community.tools import TavilySearchResults\n","\n","tool = TavilySearchResults(\n","    max_results=5,\n","    search_depth=\"advanced\",\n","    include_answer=True,\n","    include_raw_content=True,\n","    include_images=True,\n","    # include_domains=[...],\n","    # exclude_domains=[...],\n","    # name=\"...\",            # overwrite default tool name\n","    # description=\"...\",     # overwrite default tool description\n","    # args_schema=...,       # overwrite default args_schema: BaseModel\n",")"],"metadata":{"id":"m-xbcvwTCKI6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The TavilySearchResults tool takes a single \"query\" argument, which should be a natural language query:"],"metadata":{"id":"zL-5TxNFCNyK"}},{"cell_type":"code","source":["tool.invoke({\"query\": \"What happened at San Jose\"})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ILDjWzSYCPH-","executionInfo":{"status":"ok","timestamp":1726068954200,"user_tz":420,"elapsed":6984,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"65c856f2-5166-448a-c92c-a510a1962eac"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'url': 'https://www.cnn.com/us/live-news/san-jose-ca-shooting-05-27-21/index.html',\n","  'content': 'At least nine people were killed after a gunman opened fire Wednesday morning at a public transit yard in San Jose, California. Police officials say the gunman, who is believed to have taken his ...'},\n"," {'url': 'https://en.wikipedia.org/wiki/2021_San_Jose_shooting',\n","  'content': 'On May 26, 2021, a mass shooting occurred at a Santa Clara Valley Transportation Authority (VTA) rail yard in San Jose, California, United States.A 57-year-old VTA employee, Samuel James Cassidy, shot and killed nine VTA employees before committing suicide. [1] [4] It is the deadliest mass shooting in the history of the San Francisco Bay Area.[5]As a result of the shooting, service throughout ...'},\n"," {'url': 'https://www.cbsnews.com/live-updates/san-jose-shooting-9-dead/',\n","  'content': '9 people killed, suspect dead in San Jose shooting. Updated on: May 27, 2021 / 6:42 AM EDT / CBS News. An employee opened fire at a light-rail facility in San Jose, California, killing nine people ...'},\n"," {'url': 'https://www.nbcbayarea.com/news/local/south-bay/san-jose-deadly-officer-involved-shooting/3648003/?os=av&ref=app',\n","  'content': 'San Jose police on Monday continued to investigate a deadly officer-involved shooting that happened Sunday night outside a 7-Eleven on Senter Road.. What started with police officers responding to ...'},\n"," {'url': 'https://www.cnn.com/us/live-news/san-jose-ca-shooting-05-26-21/index.html',\n","  'content': \"From CNN's Eric Levenson, Stella Chan, Cheri Mossburg and Paul P. Murphy. A gunman opened fire Wednesday morning at a public transit rail yard in San Jose, California, killing at least eight co ...\"}]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["result = tool.invoke(\"What's a 'node' in LangGraph?\")"],"metadata":{"id":"k6G1uWIaC2kw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F9qAS7l3unxe","executionInfo":{"status":"ok","timestamp":1726068983975,"user_tz":420,"elapsed":15,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"b51a30e7-f081-4b6c-8679-bf750b3ed267"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n","  'content': 'Nodes¶ In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id). Similar to NetworkX, you add these nodes to a graph using the add_node method:'},\n"," {'url': 'https://medium.com/@kbdhunga/langgraph-multi-agent-collaboration-explained-c0500b0f2e61',\n","  'content': 'Nodes: Nodes in LangGraph represent individual units of computation or functionality within a graph. Nodes can be functions or runnables that perform specific tasks or operations.'},\n"," {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n","  'content': \"In LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed. State management. One of LangGraph's standout features is its automatic state ...\"},\n"," {'url': 'https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48',\n","  'content': 'Each node in a LangGraph graph has the ability to access, read, and write to the state. When a node modifies the state, it effectively broadcasts this information to all other nodes within the graph .'},\n"," {'url': 'https://adasci.org/a-practical-guide-to-building-ai-agents-with-langgraph/',\n","  'content': 'LangGraph simplifies AI agent development by focusing on three key components: State: The State is an accurate representation of the current status of the agent. Node: Nodes are the building blocks executing computations. The nodes can be LLM-based, Python code. Each graph execution builds a state, and this is passed between nodes during the ...'}]"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["len(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-gGTP0xupn4","executionInfo":{"status":"ok","timestamp":1726068992201,"user_tz":420,"elapsed":20,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"2d33b30c-73f4-4a07-e98e-9b9f1a7b9fa6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["result[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJXjG7CRur1f","executionInfo":{"status":"ok","timestamp":1726069003027,"user_tz":420,"elapsed":19,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"e4a59c8a-0a12-43b7-bdff-18a3df66fbf4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n"," 'content': 'Nodes¶ In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id). Similar to NetworkX, you add these nodes to a graph using the add_node method:'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["We can use our tool in a chain by first binding it to a tool-calling model and then calling it:"],"metadata":{"id":"L32xjEp5CoC-"}},{"cell_type":"code","source":["import datetime\n","\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import RunnableConfig, chain\n","\n","today = datetime.datetime.today().strftime(\"%D\")\n","prompt = ChatPromptTemplate(\n","    [\n","        (\"system\", f\"You are a helpful assistant. The date today is {today}.\"),\n","        (\"human\", \"{user_input}\"),\n","        (\"placeholder\", \"{messages}\"),\n","    ]\n",")\n","\n","# specifying tool_choice will force the model to call this tool.\n","llm_with_tools = llm.bind_tools([tool])\n","\n","llm_chain = prompt | llm_with_tools\n","\n","\n","@chain\n","def tool_chain(user_input: str, config: RunnableConfig):\n","    input_ = {\"user_input\": user_input}\n","    ai_msg = llm_chain.invoke(input_, config=config)\n","    tool_msgs = tool.batch(ai_msg.tool_calls, config=config)\n","    return llm_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)\n"],"metadata":{"id":"WGmoH5bJCp3_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tool_chain.invoke(\"What happened at San Jose\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1yh_adDu5xn","executionInfo":{"status":"ok","timestamp":1726069196809,"user_tz":420,"elapsed":13837,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"dd22452c-0dee-43f0-841b-1e04fd339704"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-0d2d02d89530451a99753b3a24dd6080', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"San Jose news\"}'}}]}, response_metadata={'role': 'assistant', 'content': None, 'tool_calls': [{'id': 'chatcmpl-tool-0d2d02d89530451a99753b3a24dd6080', 'type': 'function', 'function': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"San Jose news\"}'}}], 'token_usage': {'prompt_tokens': 375, 'total_tokens': 393, 'completion_tokens': 18}, 'finish_reason': 'tool_calls', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-e853bd12-46e9-4a7d-81c8-ff503f21ba2a-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'San Jose news'}, 'id': 'chatcmpl-tool-0d2d02d89530451a99753b3a24dd6080', 'type': 'tool_call'}], role='assistant')"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["### Langgraph with Web Search"],"metadata":{"id":"S3eC5ZK6C8mC"}},{"cell_type":"code","source":["from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","\n","# Uncomment the below code to list the availabe models\n","# ChatNVIDIA.get_available_models()\n","\n","\n","llm = ChatNVIDIA(\n","  model=\"meta/llama-3.1-8b-instruct\",\n","  api_key=os.environ[\"NVIDIA_API_KEY\"],\n","  temperature=0.2,\n","  top_p=0.7,\n","  max_tokens=1024,\n",")"],"metadata":{"id":"sUcDuBmqwl8S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.tools import TavilySearchResults\n","\n","tool = TavilySearchResults(\n","    max_results=5,\n","    search_depth=\"advanced\",\n","    include_answer=True,\n","    include_raw_content=True,\n","    include_images=True,\n","    # include_domains=[...],\n","    # exclude_domains=[...],\n","    # name=\"...\",            # overwrite default tool name\n","    # description=\"...\",     # overwrite default tool description\n","    # args_schema=...,       # overwrite default args_schema: BaseModel\n",")"],"metadata":{"id":"F-GLTcBHwf0R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Annotated\n","\n","from typing_extensions import TypedDict\n","\n","from langgraph.graph import StateGraph, START\n","from langgraph.graph.message import add_messages\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]\n","\n","\n","graph_builder = StateGraph(State)\n","\n","tools = [tool]\n","# Modification: tell the LLM which tools it can call\n","llm_with_tools = llm.bind_tools(tools)\n","\n","\n","def chatbot(state: State):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","\n","graph_builder.add_node(\"chatbot\", chatbot)"],"metadata":{"id":"73lqIA0cC-Tz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next we need to create a function to actually run the tools if they are called. We'll do this by adding the tools to a new node."],"metadata":{"id":"HynYuwYuDH5O"}},{"cell_type":"markdown","source":["Below, implement a BasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM's tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers."],"metadata":{"id":"9rPnUxuDDLTC"}},{"cell_type":"code","source":["import json\n","\n","from langchain_core.messages import ToolMessage\n","\n","\n","class BasicToolNode:\n","    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n","\n","    def __init__(self, tools: list) -> None:\n","        self.tools_by_name = {tool.name: tool for tool in tools}\n","\n","    def __call__(self, inputs: dict):\n","        if messages := inputs.get(\"messages\", []):\n","            message = messages[-1]\n","        else:\n","            raise ValueError(\"No message found in input\")\n","        outputs = []\n","        for tool_call in message.tool_calls:\n","            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n","                tool_call[\"args\"]\n","            )\n","            outputs.append(\n","                ToolMessage(\n","                    content=json.dumps(tool_result),\n","                    name=tool_call[\"name\"],\n","                    tool_call_id=tool_call[\"id\"],\n","                )\n","            )\n","        return {\"messages\": outputs}\n","\n","\n","tool_node = BasicToolNode(tools=[tool])\n","graph_builder.add_node(\"tools\", tool_node)"],"metadata":{"id":"nOOMLvL6DNl6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["call define a router function called route_tools, that checks for tool_calls in the chatbot's output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next."],"metadata":{"id":"yKTBPM8XDbVk"}},{"cell_type":"markdown","source":["The condition will route to tools if tool calls are present and \"__end__\" if not."],"metadata":{"id":"pSz2fOe9DeyX"}},{"cell_type":"code","source":["from typing import Literal\n","\n","\n","def route_tools(\n","    state: State,\n",") -> Literal[\"tools\", \"__end__\"]:\n","    \"\"\"\n","    Use in the conditional_edge to route to the ToolNode if the last message\n","    has tool calls. Otherwise, route to the end.\n","    \"\"\"\n","    if isinstance(state, list):\n","        ai_message = state[-1]\n","    elif messages := state.get(\"messages\", []):\n","        ai_message = messages[-1]\n","    else:\n","        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n","    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n","        return \"tools\"\n","    return \"__end__\"\n","\n","\n","# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"__end__\" if\n","# it is fine directly responding. This conditional routing defines the main agent loop.\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    route_tools,\n","    # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n","    # It defaults to the identity function, but if you\n","    # want to use a node named something else apart from \"tools\",\n","    # You can update the value of the dictionary to something else\n","    # e.g., \"tools\": \"my_tools\"\n","    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",")\n","# Any time a tool is called, we return to the chatbot to decide the next step\n","graph_builder.add_edge(\"tools\", \"chatbot\")\n","graph_builder.add_edge(START, \"chatbot\")\n","graph = graph_builder.compile()"],"metadata":{"id":"1OdxrF3wDhbA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["conditional edges start from a single node. This tells the graph \"any time the 'chatbot' node runs, either go to 'tools' if it calls a tool, or end the loop if it responds directly."],"metadata":{"id":"EmuPqlX7Do3N"}},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","try:\n","    display(Image(graph.get_graph().draw_mermaid_png()))\n","except Exception:\n","    # This requires some extra dependencies and is optional\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"6cP1ao-hDrBE","executionInfo":{"status":"ok","timestamp":1726069522444,"user_tz":420,"elapsed":192,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"27615e39-089c-4711-92fe-04f7b919089c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/jpeg":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Now we can ask the bot questions outside its training data."],"metadata":{"id":"eV6y1uS7DtKx"}},{"cell_type":"code","source":["from langchain_core.messages import BaseMessage\n","\n","while True:\n","    user_input = input(\"User: \")\n","    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n","        print(\"Goodbye!\")\n","        break\n","    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n","        for value in event.values():\n","            if isinstance(value[\"messages\"][-1], BaseMessage):\n","                print(\"Assistant:\", value[\"messages\"][-1].content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q09PxGWWDuZ5","executionInfo":{"status":"ok","timestamp":1726069834964,"user_tz":420,"elapsed":80749,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"84d71c30-f92a-486a-c850-b8e95fc69c15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["User: Tell me more about langgraph\n","Assistant: \n","Assistant: [{\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"LangGraph is a framework for creating stateful, multi-actor applications with LLMs, using cycles, controllability, and persistence. It integrates with LangChain and LangSmith, and supports human-in-the-loop and streaming features.\"}, {\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph is a framework for building stateful, multi-actor agents with LLMs that can handle complex scenarios and collaborate with humans. Learn how to use LangGraph with Python or JavaScript, and deploy your agents at scale with LangGraph Cloud.\"}, {\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. Learn how to use LangGraph to create stateful, flexible, and scalable systems with nodes, edges, and state management.\"}, {\"url\": \"https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141\", \"content\": \"3. LangGraph is a powerful tool for building stateful, multi-actor applications with Large Language Models (LLMs). It extends the LangChain library, allowing you to coordinate multiple chains (or ...\"}, {\"url\": \"https://blog.langchain.dev/langgraph-studio-the-first-agent-ide/\", \"content\": \"LangGraph Studio is a desktop app that lets you visualize, interact with, and debug complex agentic applications built with LangGraph, a low-level orchestration framework. Learn how to use it with LangSmith, a platform for creating and managing agents, and see examples of agent graphs and interactions.\"}]\n","Assistant: LangGraph is a framework for creating stateful, multi-actor applications with LLMs, using cycles, controllability, and persistence. It integrates with LangChain and LangSmith, and supports human-in-the-loop and streaming features. LangGraph is a powerful tool for building stateful, multi-actor applications with Large Language Models (LLMs). It extends the LangChain library, allowing you to coordinate multiple chains (or \"actors\") and manage their state. LangGraph Studio is a desktop app that lets you visualize, interact with, and debug complex agentic applications built with LangGraph.\n","User: Tell me more about langchain\n","Assistant: \n","Assistant: [{\"url\": \"https://js.langchain.com/v0.1/docs/get_started/introduction/\", \"content\": \"Langchain is a framework for developing applications powered by language models. It consists of libraries, templates, and tools for connecting, reasoning, and deploying language models.\"}, {\"url\": \"https://js.langchain.com/v0.1/docs/get_started/quickstart/\", \"content\": \"Langchain is a framework that enables connecting external data and computation to LLMs. Learn how to use Langchain components, such as prompt templates, models, output parsers, and expression language, to build simple and complex applications with LLMs.\"}, {\"url\": \"https://python.langchain.com/v0.2/docs/introduction/\", \"content\": \"LangChain is a framework for developing applications powered by large language models (LLMs). Learn how to use LangChain's open-source libraries, components, and integrations to build, deploy, and evaluate LLM applications and agents.\"}, {\"url\": \"https://en.wikipedia.org/wiki/LangChain\", \"content\": \"In October 2023 LangChain introduced LangServe, a deployment tool designed to facilitate the transition from LCEL (LangChain Expression Language) prototypes to production-ready applications.[5]\\nIntegrations[edit]\\nAs of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \\\"todo\\\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database[6] to store and retrieve vector embeddings; Weaviate vector database[7] to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK.[8] As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.[2]\\nHistory[edit]\\nLangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.[3][4]\\n The project quickly garnered popularity, with improvements from hundreds of contributors on GitHub, trending discussions on Twitter, lively activity on the project's Discord server, many YouTube tutorials, and meetups in San Francisco and London. As of April 2023, it can read from more than 50 document types and data sources.[9]\\nReferences[edit]\\nExternal links[edit]\"}, {\"url\": \"https://www.langchain.com/langchain\", \"content\": \"Augment the power\\nof\\u00a0LLMs with your data\\nLangChain helps connect LLMs to your company\\u2019s private sources\\nof data and APIs to create context-aware, reasoning applications.\\n Our Methods\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. The largest community building the future of LLM apps\\nLangChain\\u2019s flexible abstractions and AI-first toolkit make it\\u00a0the\\u00a0#1\\u00a0choice for developers when building with GenAI.\\n Why choose LangChain?\\nLangChain is easy to get started with and\\u00a0gives\\u00a0you choice, flexibility, and power as\\u00a0you scale.\\n Get customizability and control with a durable runtime baked in\\nLangChain Expression Language (LCEL) lets you build your app in a truly composable way, allowing you to customize it as you see fit.\"}]\n","Assistant: Langchain is a framework for developing applications powered by language models. It consists of libraries, templates, and tools for connecting, reasoning, and deploying language models. Langchain is a framework that enables connecting external data and computation to LLMs. It includes integrations with various systems, such as cloud storage, API wrappers, web scraping subsystems, and language models. Langchain also provides a flexible abstractions and AI-first toolkit, making it the #1 choice for developers when building with GenAI. It is easy to get started with and gives you choice, flexibility, and power as you scale. Langchain Expression Language (LCEL) lets you build your app in a truly composable way, allowing you to customize it as you see fit.\n","User: quit\n","Goodbye!\n"]}]},{"cell_type":"markdown","source":["### Adding Memory to the Chatbot"],"metadata":{"id":"UspQHh0LDxUv"}},{"cell_type":"markdown","source":["LangGraph solves this problem through persistent checkpointing. If you provide a checkpointer when compiling the graph and a thread_id when calling your graph, LangGraph automatically saves the state after each step. When you invoke the graph again using the same thread_id, the graph loads its saved state, allowing the chatbot to pick up where it left off."],"metadata":{"id":"3p3c1RWrD1xK"}},{"cell_type":"code","source":["from langgraph.checkpoint.memory import MemorySaver\n","\n","#create a MemorySaver checkpointer\n","memory = MemorySaver()"],"metadata":{"id":"dpfTO_WDD4Ix"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["we're using an in-memory checkpointer. This is convenient for our tutorial (it saves it all in-memory). In a production application, you would likely change this to use SqliteSaver or PostgresSaver and connect to your own DB."],"metadata":{"id":"yRJjtRCED-jg"}},{"cell_type":"markdown","source":["Next define the graph. Now that you've already built your own BasicToolNode, we'll replace it with LangGraph's prebuilt ToolNode and tools_condition, since these do some nice things like parallel API execution."],"metadata":{"id":"yO3gBFriEGih"}},{"cell_type":"code","source":["from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","\n","# Uncomment the below code to list the availabe models\n","# ChatNVIDIA.get_available_models()\n","\n","\n","llm = ChatNVIDIA(\n","  model=\"meta/llama-3.1-8b-instruct\",\n","  api_key=os.environ[\"NVIDIA_API_KEY\"],\n","  temperature=0.2,\n","  top_p=0.7,\n","  max_tokens=1024,\n",")"],"metadata":{"id":"IZbJq2H_yeLY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Annotated\n","\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from langchain_core.messages import BaseMessage\n","from typing_extensions import TypedDict\n","\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.graph.message import add_messages\n","from langgraph.prebuilt import ToolNode, tools_condition\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]\n","\n","\n","graph_builder = StateGraph(State)\n","\n","\n","tool = TavilySearchResults(max_results=2)\n","tools = [tool]\n","llm_with_tools = llm.bind_tools(tools)\n","\n","\n","def chatbot(state: State):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","\n","graph_builder.add_node(\"chatbot\", chatbot)\n","\n","tool_node = ToolNode(tools=[tool])\n","graph_builder.add_node(\"tools\", tool_node)\n","\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    tools_condition,\n",")\n","# Any time a tool is called, we return to the chatbot to decide the next step\n","graph_builder.add_edge(\"tools\", \"chatbot\")\n","graph_builder.add_edge(START, \"chatbot\")"],"metadata":{"id":"VNS73CnoEIa3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, compile the graph with the provided checkpointer."],"metadata":{"id":"-n0l31NJEMdO"}},{"cell_type":"code","source":["graph = graph_builder.compile(checkpointer=memory)"],"metadata":{"id":"a4To09pvENsH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","try:\n","    display(Image(graph.get_graph().draw_mermaid_png()))\n","except Exception:\n","    # This requires some extra dependencies and is optional\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"yfmOrMTSEQW9","executionInfo":{"status":"ok","timestamp":1726070004268,"user_tz":420,"elapsed":213,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"32ef0f19-5f50-433e-bee2-15741eeac5cb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/jpeg":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Now you can interact with your bot! First, pick a thread to use as the key for this conversation."],"metadata":{"id":"lsm-EdWhESx5"}},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"1\"}}"],"metadata":{"id":"XCbUAnFUEUJI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_input = \"Hi there! My name is SJSU.\"\n","\n","# The config is the **second positional argument** to stream() or invoke()!\n","events = graph.stream(\n","    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",")\n","for event in events:\n","    event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fhLGjYkEVW1","executionInfo":{"status":"ok","timestamp":1726070225815,"user_tz":420,"elapsed":5086,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"9bfb19b0-e2ba-40a6-b440-31bb8f564f44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Hi there! My name is SJSU.\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Nice to meet you, SJSU! It's a unique name, is it a nickname or a reference to San Jose State University?\n"]}]},{"cell_type":"code","source":["len(event['messages'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GAk-Ahk8y9Ju","executionInfo":{"status":"ok","timestamp":1726070233599,"user_tz":420,"elapsed":19,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"44c298b7-6791-46df-c3c5-c9e9ca6f5b85"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["event['messages'][-2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9amSjDfzGUI","executionInfo":{"status":"ok","timestamp":1726070254796,"user_tz":420,"elapsed":22,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"70b4bd97-5583-49ca-8cef-8e7754aec9a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["HumanMessage(content='Hi there! My name is SJSU.', id='c3ffa6ba-d523-46d3-b5db-932864965583')"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["event['messages'][-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ww2b43LnzHdH","executionInfo":{"status":"ok","timestamp":1726070258858,"user_tz":420,"elapsed":21,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"d6d786e0-ada9-4afe-ca39-362c2874df01"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AIMessage(content=\"Nice to meet you, SJSU! It's a unique name, is it a nickname or a reference to San Jose State University?\", response_metadata={'role': 'assistant', 'content': \"Nice to meet you, SJSU! It's a unique name, is it a nickname or a reference to San Jose State University?\", 'token_usage': {'prompt_tokens': 354, 'total_tokens': 382, 'completion_tokens': 28}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-11db8315-bf75-4ad9-b3ad-787de5da2a6a-0', role='assistant')"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","source":["The config was provided as the second positional argument when calling our graph. It importantly is not nested within the graph inputs ({'messages': []})."],"metadata":{"id":"olwGenImEZhQ"}},{"cell_type":"code","source":["user_input = \"Remember my name?\"\n","\n","# The config is the **second positional argument** to stream() or invoke()!\n","events = graph.stream(\n","    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",")\n","for event in events:\n","    event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sZGk6zDEbZ7","executionInfo":{"status":"ok","timestamp":1726070268378,"user_tz":420,"elapsed":4801,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"3ebfa0e3-5224-4671-a0a8-943dff82f6fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Remember my name?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I'll remember your name as SJSU for our conversation.\n"]}]},{"cell_type":"code","source":["# The only difference is we change the `thread_id` here to \"2\" instead of \"1\"\n","events = graph.stream(\n","    {\"messages\": [(\"user\", user_input)]},\n","    {\"configurable\": {\"thread_id\": \"2\"}},\n","    stream_mode=\"values\",\n",")\n","for event in events:\n","    event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQoE5IykEiHr","executionInfo":{"status":"ok","timestamp":1726070283236,"user_tz":420,"elapsed":7633,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"00c7d7a1-44d1-4ff0-bfd5-d359cd8e80da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Remember my name?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","I'm happy to chat with you, but I don't have any prior knowledge or memory of our previous conversations. Each time you interact with me, it's a new conversation and I don't retain any information from previous chats.\n"]}]},{"cell_type":"markdown","source":["By now, we have made a few checkpoints across two different threads. But what goes into a checkpoint? To inspect a graph's state for a given config at any time, call get_state(config)."],"metadata":{"id":"z4eAiVmAElFb"}},{"cell_type":"code","source":["snapshot = graph.get_state(config)\n","snapshot"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdQHOMCjEmNz","executionInfo":{"status":"ok","timestamp":1726070293407,"user_tz":420,"elapsed":28,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"86dd1dc6-8d39-4ca6-f43c-db5e7123185e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["StateSnapshot(values={'messages': [HumanMessage(content='Hi there! Good Morning.', id='2c99bc70-434c-43e4-85a8-86bd9ec93f3b'), AIMessage(content=\"Good morning! It's nice to meet you. Is there anything I can help you with today?\", response_metadata={'role': 'assistant', 'content': \"Good morning! It's nice to meet you. Is there anything I can help you with today?\", 'token_usage': {'prompt_tokens': 314, 'total_tokens': 334, 'completion_tokens': 20}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-b70e9acf-419c-4348-80c9-b295e208871b-0'), HumanMessage(content='Hi there! My name is SJSU.', id='c3ffa6ba-d523-46d3-b5db-932864965583'), AIMessage(content=\"Nice to meet you, SJSU! It's a unique name, is it a nickname or a reference to San Jose State University?\", response_metadata={'role': 'assistant', 'content': \"Nice to meet you, SJSU! It's a unique name, is it a nickname or a reference to San Jose State University?\", 'token_usage': {'prompt_tokens': 354, 'total_tokens': 382, 'completion_tokens': 28}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-11db8315-bf75-4ad9-b3ad-787de5da2a6a-0'), HumanMessage(content='Remember my name?', id='b4dbe494-fe94-4963-97d8-30473ddf2b32'), AIMessage(content=\"I'll remember your name as SJSU for our conversation.\", response_metadata={'role': 'assistant', 'content': \"I'll remember your name as SJSU for our conversation.\", 'token_usage': {'prompt_tokens': 396, 'total_tokens': 409, 'completion_tokens': 13}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-b40c1432-350a-4200-8151-6a9823ad9fa6-0')]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef70569-77f8-6610-8007-87efbc80ac32'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content=\"I'll remember your name as SJSU for our conversation.\", response_metadata={'role': 'assistant', 'content': \"I'll remember your name as SJSU for our conversation.\", 'token_usage': {'prompt_tokens': 396, 'total_tokens': 409, 'completion_tokens': 13}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-8b-instruct'}, id='run-b40c1432-350a-4200-8151-6a9823ad9fa6-0')]}}, 'step': 7, 'parents': {}}, created_at='2024-09-11T15:57:48.298947+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1ef70569-4b01-6b8b-8006-5eb314625a14'}}, tasks=())"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","source":["The snapshot above contains the current state values, corresponding config, and the next node to process. In our case, the graph has reached an __end__ state, so next is empty."],"metadata":{"id":"8yXYirkJErB2"}},{"cell_type":"markdown","source":["chatbot can now maintain conversation state across sessions thanks to LangGraph's checkpointing system. LangGraph's checkpointing even handles arbitrarily complex graph states, which is much more expressive and powerful than simple chat memory."],"metadata":{"id":"pVimoVC5Eu34"}},{"cell_type":"markdown","source":["### Human-in-the-loop"],"metadata":{"id":"NMDLMQT_E23K"}},{"cell_type":"markdown","source":["Agents can be unreliable and may need human input to successfully accomplish tasks. Similarly, for some actions, you may want to require human approval before running to ensure that everything is running as intended. This can be in several ways, but the primary supported way is to add an \"interrupt\" before a node is executed. This interrupts execution at that node. You can then resume from that spot to continue.\n","\n"],"metadata":{"id":"X5igN3g2E6vF"}},{"cell_type":"markdown","source":["we will use LangGraph's interrupt_before functionality to always break the tool node. You can accomplish similar functionality using either `interrupt_before` or `interrupt_after` in the create_react_agent(model, tools=tool, interrupt_before=[\"tools\" | \"agent\"], interrupt_after=[\"tools\" | \"agent\"]) constructor.\n","\n","https://langchain-ai.github.io/langgraph/reference/prebuilt/#create_react_agent"],"metadata":{"id":"59YhRuTZE-DL"}},{"cell_type":"code","source":["from langchain_nvidia_ai_endpoints import ChatNVIDIA\n","\n","# Uncomment the below code to list the availabe models\n","# ChatNVIDIA.get_available_models()\n","\n","\n","llm = ChatNVIDIA(\n","  model=\"meta/llama-3.1-8b-instruct\",\n","  api_key=os.environ[\"NVIDIA_API_KEY\"],\n","  temperature=0.2,\n","  top_p=0.7,\n","  max_tokens=1024,\n",")"],"metadata":{"id":"_MGeqI34zyOE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode\n","\n","We can now wrap these tools in a simple ToolNode. This is a simple class that takes in a list of messages containing an AIMessages with tool_calls, runs the tools, and returns the output as ToolMessages."],"metadata":{"id":"wWIde-U52MHz"}},{"cell_type":"code","source":["from typing import Annotated\n","\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from typing_extensions import TypedDict\n","\n","from langgraph.checkpoint.memory import MemorySaver\n","from langgraph.graph import StateGraph, START\n","from langgraph.graph.message import add_messages\n","from langgraph.prebuilt import ToolNode, tools_condition\n","\n","memory = MemorySaver()\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]\n","\n","\n","graph_builder = StateGraph(State)\n","\n","\n","tool = TavilySearchResults(max_results=2)\n","tools = [tool]\n","\n","#we should make sure the model knows that it has these tools available to call.\n","#We can do this by converting the LangChain tools into the format for LLM function calling, and then bind them to the model class.\n","llm_with_tools = llm.bind_tools(tools)\n","\n","\n","def chatbot(state: State):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","\n","graph_builder.add_node(\"chatbot\", chatbot)\n","\n","#We can now wrap these tools in a simple ToolNode. This is a simple class that takes in a list of messages containing an AIMessages with tool_calls,\n","#runs the tools, and returns the output as ToolMessages.\n","tool_node = ToolNode(tools=[tool])\n","graph_builder.add_node(\"tools\", tool_node)\n","\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    tools_condition,\n",")\n","graph_builder.add_edge(\"tools\", \"chatbot\")\n","graph_builder.add_edge(START, \"chatbot\")"],"metadata":{"id":"h61Qi4voE_tw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, compile the graph, specifying to interrupt_before the tools node. To always interrupt before a particular node, pass the name of the node to compile"],"metadata":{"id":"tRZDXm30FGRl"}},{"cell_type":"code","source":["graph = graph_builder.compile(\n","    checkpointer=memory,\n","    # This is new!\n","    interrupt_before=[\"tools\"],\n","    # Note: can also interrupt __after__ tools, if desired.\n","    # interrupt_after=[\"tools\"]\n",")"],"metadata":{"id":"c7X6C-LDFHeG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n","config = {\"configurable\": {\"thread_id\": \"1\"}}\n","# The config is the **second positional argument** to stream() or invoke()!\n","events = graph.stream(\n","    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",")\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vkwNqFoBFJBx","executionInfo":{"status":"ok","timestamp":1726070361687,"user_tz":420,"elapsed":10358,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"7af66616-8540-479d-9ccc-7bd5fd41fa4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","I'm learning LangGraph. Could you do some research on it for me?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  tavily_search_results_json (chatcmpl-tool-e27a0088aba041949bb217750735f223)\n"," Call ID: chatcmpl-tool-e27a0088aba041949bb217750735f223\n","  Args:\n","    query: LangGraph\n"]}]},{"cell_type":"markdown","source":["Let's inspect the graph state to confirm it worked."],"metadata":{"id":"_W-7V_mPFLYO"}},{"cell_type":"code","source":["snapshot = graph.get_state(config)\n","snapshot.next"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5KCOXm8FMjN","executionInfo":{"status":"ok","timestamp":1726070367982,"user_tz":420,"elapsed":28,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"15424918-105b-464b-dd69-96ab25bbf0ba"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('tools',)"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["existing_message = snapshot.values[\"messages\"][-1]\n","existing_message.tool_calls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrJ8unqyFQK0","executionInfo":{"status":"ok","timestamp":1726070372194,"user_tz":420,"elapsed":22,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"4189bb90-371d-4fdc-acd8-173f2796fa54"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'name': 'tavily_search_results_json',\n","  'args': {'query': 'LangGraph'},\n","  'id': 'chatcmpl-tool-e27a0088aba041949bb217750735f223',\n","  'type': 'tool_call'}]"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["# `None` will append nothing new to the current state, letting it resume as if it had never been interrupted\n","events = graph.stream(None, config, stream_mode=\"values\")\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0_9YF_BuFcUD","executionInfo":{"status":"ok","timestamp":1726070394237,"user_tz":420,"elapsed":11320,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"716a4e32-c2da-450a-e81a-58cfa3cff1d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  tavily_search_results_json (chatcmpl-tool-e27a0088aba041949bb217750735f223)\n"," Call ID: chatcmpl-tool-e27a0088aba041949bb217750735f223\n","  Args:\n","    query: LangGraph\n","=================================\u001b[1m Tool Message \u001b[0m=================================\n","Name: tavily_search_results_json\n","\n","[{\"url\": \"https://www.langchain.com/langgraph\", \"content\": \"LangGraph is a framework for building stateful, multi-actor agents with LLMs that can handle complex scenarios and collaborate with humans. Learn how to use LangGraph with Python or JavaScript, and deploy your agents at scale with LangGraph Cloud.\"}, {\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph is a library within the LangChain ecosystem that simplifies the development of complex, multi-agent large language model (LLM) applications. Learn how to use LangGraph to create stateful, flexible, and scalable systems with nodes, edges, and state management.\"}]\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Based on the search results, LangGraph is a framework for building stateful, multi-actor agents with LLMs that can handle complex scenarios and collaborate with humans. It is part of the LangChain ecosystem and can be used with Python or JavaScript. LangGraph simplifies the development of complex, multi-agent LLM applications by providing a library for node, edge, and state management.\n"]}]},{"cell_type":"markdown","source":["### Customize the bot's behavior using custom state updates."],"metadata":{"id":"uM1qnM4ZFl3W"}},{"cell_type":"markdown","source":["we showed how to interrupt a graph so that a human could inspect its actions. This lets the human read the state, but if they want to change their agent's course, they'll need to have write access.\n","\n","LangGraph lets you manually update state! Updating the state lets you control the agent's trajectory by modifying its actions (even modifying the past!). This capability is particularly useful when you want to correct the agent's mistakes, explore alternative paths, or guide the agent towards a specific goal."],"metadata":{"id":"emxjRQ8GFtz5"}},{"cell_type":"code","source":["from typing import Annotated\n","\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from typing_extensions import TypedDict\n","\n","from langgraph.checkpoint.memory import MemorySaver\n","from langgraph.graph import StateGraph, START\n","from langgraph.graph.message import add_messages\n","from langgraph.prebuilt import ToolNode, tools_condition\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]\n","\n","\n","graph_builder = StateGraph(State)\n","\n","\n","tool = TavilySearchResults(max_results=2)\n","tools = [tool]\n","\n","llm_with_tools = llm.bind_tools(tools)\n","\n","\n","def chatbot(state: State):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","\n","graph_builder.add_node(\"chatbot\", chatbot)\n","\n","tool_node = ToolNode(tools=[tool])\n","graph_builder.add_node(\"tools\", tool_node)\n","\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    tools_condition,\n",")\n","graph_builder.add_edge(\"tools\", \"chatbot\")\n","graph_builder.add_edge(START, \"chatbot\")\n","memory = MemorySaver()\n","graph = graph_builder.compile(\n","    checkpointer=memory,\n","    # This is new!\n","    interrupt_before=[\"tools\"],\n","    # Note: can also interrupt **after** actions, if desired.\n","    # interrupt_after=[\"tools\"]\n",")\n","\n","user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n","config = {\"configurable\": {\"thread_id\": \"1\"}}\n","# The config is the **second positional argument** to stream() or invoke()!\n","events = graph.stream({\"messages\": [(\"user\", user_input)]}, config)\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"],"metadata":{"id":"KNDgI-4nFybZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["snapshot = graph.get_state(config)\n","existing_message = snapshot.values[\"messages\"][-1]\n","existing_message.pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElCtgEMYF3EU","executionInfo":{"status":"ok","timestamp":1726072720020,"user_tz":420,"elapsed":32,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"86d598a7-6e86-437e-e4cb-8e3c4c4cc47b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  tavily_search_results_json (chatcmpl-tool-7766e89b71d042eb880822c7542f8ad1)\n"," Call ID: chatcmpl-tool-7766e89b71d042eb880822c7542f8ad1\n","  Args:\n","    query: LangGraph\n"]}]},{"cell_type":"code","source":["from langchain_core.messages import AIMessage, ToolMessage\n","\n","answer = (\n","    \"LangGraph is a library for building stateful, multi-actor applications with LLMs.\"\n",")\n","new_messages = [\n","    # The LLM API expects some ToolMessage to match its tool call. We'll satisfy that here.\n","    ToolMessage(content=answer, tool_call_id=existing_message.tool_calls[0][\"id\"]),\n","    # And then directly \"put words in the LLM's mouth\" by populating its response.\n","    AIMessage(content=answer),\n","]\n","\n","new_messages[-1].pretty_print()\n","graph.update_state(\n","    # Which state to update\n","    config,\n","    # The updated values to provide. The messages in our `State` are \"append-only\", meaning this will be appended\n","    # to the existing state. We will review how to update existing messages in the next section!\n","    {\"messages\": new_messages},\n",")\n","\n","print(\"\\n\\nLast 2 messages;\")\n","print(graph.get_state(config).values[\"messages\"][-2:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpwxjAayGBX3","executionInfo":{"status":"ok","timestamp":1726072726726,"user_tz":420,"elapsed":38,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"1769dc61-621c-4b22-d4f5-330791c17b41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","LangGraph is a library for building stateful, multi-actor applications with LLMs.\n","\n","\n","Last 2 messages;\n","[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='7a6e8c97-dba3-428e-8347-6e57651a11dc', tool_call_id='chatcmpl-tool-7766e89b71d042eb880822c7542f8ad1'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='29d7b79b-db9b-42c3-9d38-ab2147c171e3')]\n"]}]},{"cell_type":"code","source":["graph.update_state(\n","    config,\n","    {\"messages\": [AIMessage(content=\"I'm an AI expert!\")]},\n","    # Which node for this function to act as. It will automatically continue\n","    # processing as if this node just ran.\n","    as_node=\"chatbot\",\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjPuEAF9GGCZ","executionInfo":{"status":"ok","timestamp":1726072745818,"user_tz":420,"elapsed":47,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"a864fd18-112f-47e3-f358-eb3a92fae3d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'configurable': {'thread_id': '1',\n","  'checkpoint_ns': '',\n","  'checkpoint_id': '1ef705c5-c2de-6eee-8003-182508afa521'}}"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["from IPython.display import Image, display\n","\n","try:\n","    display(Image(graph.get_graph().draw_mermaid_png()))\n","except Exception:\n","    # This requires some extra dependencies and is optional\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":308},"id":"sFsMyIMfGIEs","executionInfo":{"status":"ok","timestamp":1726072751182,"user_tz":420,"elapsed":2098,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"09881357-8c98-45c9-c625-2a0ab082d36f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAEjATADASIAAhEBAxEB/8QAHQABAAMBAAMBAQAAAAAAAAAAAAQFBgcCAwgBCf/EAFgQAAEEAQIDAgYMCgYGBwkAAAEAAgMEBQYRBxIhEzEVFiJBVpQIFBc2UVR0k7LR0tQjMjVVYXF1gbTTMzRikaGxJCVzkrPECUJDUlNjciZERleDhJWi4f/EABoBAQEAAwEBAAAAAAAAAAAAAAABAgMEBQb/xAA1EQEAAQIBCAkDBAIDAAAAAAAAAQIRAxIxQVFSYaHRBBQhM3GBkbHBBROSFSIjYiQyouHw/9oADAMBAAIRAxEAPwD+qaIiAiIgIiICIiAiIgIiICIiAirc5mm4avHywvt2539lXqxEB0r/ANZ6AAbkuPQAE/oVT4kxZkdrqWU5qR2x9pv6Uov7LYu54/tScx/UOg3U0RbKrm0cVtrW0upMRA8tkylKNw7w6wwH/NePjVhfzxQ9ZZ9a8ItI4KFgZHhcdGwdzW1IwP8AJefirhfzPQ9WZ9Sy/h38DsPGrC/nih6yz608asL+eKHrLPrTxVwv5noerM+pPFXC/meh6sz6k/h38F7Dxqwv54oess+tPGrC/nih6yz608VcL+Z6HqzPqTxVwv5noerM+pP4d/A7Dxqwv54oess+tecOosVZeGQ5OnK8/wDVZYYT/gV4eKuF/M9D1Zn1Lwl0fgZ28smEx0jd99nVIyP8k/h38DsW6LMeKD8CO201KKJYPyZM9xpS9e7bYmI+YOZ0HeWv22VxhcxFm6XbxxyQPa4xzV5wBJDIPxmOAJG4+EEggggkEE4VUREZVM3j/wBnSyeiItSCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIMxidsvrbNXHgObihHjYB18hz2MnlPweUHwj/6f61p1mdMt9p6n1ZUcCHS24b7NxsDHJAyMdfP5cEi0y6Mb/aI3R7Qsi9Vq1DSrTWLErIK8LDJJLI4NaxoG5cSe4Add17VAz8NexgsjFapvyNWStI2WnG3mdOwtIdGBuNy4bjbfzrnRyjP+yp0ZDww1frDTtixqJmn6Htw120bUAn5+YQlrnQ9Y3uaR2rQ5gALidgSr2Dj/pGLh9j9XZG1ex+OtytqtbNiLrZnWCznLGQmHtXjYOIcGEENJB6LhOn9P6v1Fw24oaD05itVDQr9JSVcDV1nR9qXKl1zJWCjC9+zpYQwMAc7mDTs0PIWp1VrnUmptA6DOPwmu9O6eiutp6nix+InhzDI2Vd2CFgaZDEZuVr5IhvsDsQNyg6lY9kJw9q6LxurJdTQM0/kLvg6C4YZf6z5f4J7OTmjcOzfuHgbEbHqRvl8v7KjTmO4gaS0/HRzEtHO0bVz267CZBssRilbExnYe1+fynF+7jsGBrSekjSeMaR0JnG4/H036V1NDBHxgr52NmaglsTig+ruyzLKS/fZw8tznEtd0fs5dk4wzZDSXGvh5rRun8znsJTx2UxtvwHRfcnryTe13xOdEzd3KexeOYDYHbfbdB29F4sdzsa4AgEb7EbFeSAsxLtiOINcx7NhzFSQStG/WeHl5HfBuY3vBPf5DB126adZjLj25r7T8DNyalezckO3Ru4ZE0E/Ced+3/oP6N+jBzzE5rT7XjjZYadERc6CIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIKLP4uyLtbM42NsuRqsdE6BzuUWYXEF0e/cHAtBaT0B3HQOcV6rMGnOJun7eMyFOpmsbIWsuYy/CHhrmuDwyWJw6OBDTs4eYH4FolT5nSWLzszbFmB8dxg5WW6sz4J2j4BIwh236N9v0LfFVNURTiaNK+LIM9jfwpicSzhxpdhILd24mAdCNiPxfOCQpGL9j/wzwmSqZHH6A03Sv1JWz17NfFwskikad2va4N3BBAIIVv4kStHLHqbPRtHm9sxu/xdGT/iniTY9Ks989D/AClft4e3wktGtqEWX8SbHpVnvnof5SzvEbDZPS3D3VGao6pzJu47F2rkAmlhLO0jic9vN+DHTcDfqE+3h7fCS0a3SkWNxekbdzGVLEmqs72ksLJHcssO25aCf+yUrxJselWe+eh/lJ9vD2+Elo1qKx7HPhXbsSzz8OtMTTSuL3yPxMBc5xO5JPL1JK8D7GzhO4knhvpYk95OIg+ytB4k2PSrPfPQ/wApBoeQkdrqXPSt335TZYz/ABYwH/FPt4e3wktGtMmu4nROJo46rXZBFDE2vQxVCMc7msAa2OKMbbNaNh5mtHUloBI89PYiepJbyF/s3ZW85pm7IlzImN37OJpPUhoJ67Ddznu2HNsPZhdL4zT7pJKVbaxIOWS1NI6aeQd4DpXkvcN9+hPnKtVjVVTTE00ac8ngIiLSgiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICxnGkgcHNdlxIb4Bv7kfJ3/pH+YWzWM407+45rvbYHwDf/GAI/q7+/fp/f0QaTAfkLHfJo/ohT1AwH5Cx3yaP6IU9AREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBYvjWN+DWvQXBo8AX/KcNwP9Hk6lbRYvjZt7jWvd+g8AX99hv8A+7yebzoNLgPyFjfk0f0Qp6gYD8hY35NH9EKegIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIqvUOejwFSN5ifZszv7GtWj6OmkIJ23PQAAEknuAJ/Qs67PavcSRjsIwH/qm7M7b9/ZDf+5dFGBXiRlRm3zZbNsixHh3WHxDB+tzfy08O6w+IYP1ub+WtnVa9cesFm3Xzh7ODj3Y4IcNBD4rS57H6lr3MTNdZbELaMj4do+ZpjeH8wdIdun9H59+nWPDusPiGD9bm/lrD8a9AZrjjw2y+j8zSwsNa8wGO1HYlc+vK07skaDH3gj94JHnTqteuPWCz89iZx8veyE0FYzkmk36ZxdOVlGrLJeFg3HMb+EcB2bOVrfJG/Xclw6cvXuC5Fwz01nOFWgsHpPDY3CNx+KrNrsc61NzSHvc934P8Zzi5x/SStN4d1h8Qwfrc38tOq1649YLNuixHh3WHxDB+tzfy08O6w+IYP1ub+WnVa9cesFm3RYpmf1cw8z8ZhpWjvYy7K0n9RMR/y+taTBZuDP48WoWviIe6KWCUAPhkadnMcB03BHeCQRsQSCCdWJgV4cZU5t03LLFERaEEREBERAREQEREBERAREQEREBERAREQEREBERAREQYzWx/9qNJjzdtZP7+wd//AFWCr9be+nSX+2s/8EqwXqR3VHh8ys6BEVPqHV2J0rLiI8pb9qvy15mNpDs3v7Ww9r3tZ5IPLu2N53dsOnf1CxRcIii5TK08HjbWRyNqGjQqxOmns2HhkcUbRu5znHoAACSSqJSKkyGtcLi8np/H2bwZbz8j4saxsb3Cw5kTpnbOAIbtGxzt3EA7bDr0V2oCKFmc1Q05ireTylyDH46pGZZ7VmQRxxMHe5zj0AUxrg9ocDuCNwVR+qFw9P8AperB5hl+g/8Ata5/zJU1QeHv9c1d+2P+UrK1d1X4R7wsaWxREXloIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgxmtvfTpL/bWf+CVYKv1t76dJf7az/wAEqwXqR3VHh8ys6HI+Pucykd3QOl8fl7Ona2p857Qu5Wm4MnjibBLN2UTyPIfI6NrA4dR126rGcauHDcDieGmCr6m1HOy3ryo4X72SdZuVwalkFsU0gLgOhIJ3ILiQR027lrTQ2B4iYGTDajxsWUx0j2ydlKS0te07texzSHMcPM5pBHwqhxHA/ReDp0K1TESCOjlGZqB016xNILjYzE2Vz3yFzyGOLdnEjbbp0C1zF0cXuaos6Fi4oaKuZ3VWZrVctiKWCfXyX+tXTXY2OFZtuTq1peHeW47tY52x3AWWyh1LJwm9kTo3U1zJiLB4eC/TimzsuQsQCWtLIY3WyyN8jCYQSxwI2c5pLmnr9NZ3g/pDUrtQuyeGbafn31pMg508rXSPrgCB7SHAxuYANnR8p3677r0ac4JaJ0ocscbg2RnL1BSyRmsSz+3ovL6T9o93au2keOd+7tjtvt0WOTI4zq7h9VbkeAeCgzWfjr3L9uZ17wvPJcZvi5XFsc73Oexp222aRsCdtu9UuU1fqvTOSz/Datq3K2sY3WWHwkWpLM4kyFSrdrmaWHtyOsjXMEbXu3cO2HnA27YPY2cOxgqeHODndQpWHWqrH5S259eQsEfNG8y87NmNAAaQBt02VrU4JaHo6Gt6Pi07W8Xrkhns1ZHPe6aUkO7V8rnGR0m7WkPLuYco2PQJkyPmzjnUuYHTHGjQPjBnM5gqelaueryZDIyz2Kc7pZWPgdMTzvjeI2v5Hkjv8xX1forTlbSunatCpcyF+ADtBPk78t2Y83X+llc5xHwDfYDuVNpzgzozSuCzWHoYOM0c00syQtzSWpLjSws5ZZZXOe8BpIALugJ22VpobQOE4cYTwRgK01XH9oZRFPbmskHla3o6V7nAbNaA0HYbdAsoi03GhUHh7/XNXftj/lKynKDw9/rmrv2x/wApWWyruq/CPeFjS2KIi8tBERAREQEREBERAREQEREBERAREQEREBERAREQEREGM1t76dJf7az/AMEqwVdqmyM9fxLMLG7IX6lqcixE4GpA6NhZJFYkB3YXF4aA0OcH7HkIY/aMcpn2HY6PyLyO8x2qhaf1bzA/4BephzFeHTETHZ2dsxGmZ0+LLOukVJ4Wz3oZlfWqX89PC2e9DMr61S/nrPI/tH5RzLLtFSeFs96GZX1ql/PVPrHiNNoDTGR1FqDTWRxuGx8Rms2pLFQhjd9u4TEkkkAAAkkgBMj+0flHMs2aLK4DWd/VGEoZjFaWyVzG34GWa1hlmntJG4AtPWfcdD3HqFP8LZ70MyvrVL+emR/aPyjmWXaKk8LZ70MyvrVL+enhbPehmV9apfz0yP7R+Ucyy7UHh7/XNXftj/lKyiMyWoJTyt0jfice51i3VDP3lsrj/cCvZh8fn9FVcrbnij1A21NFZNPGx9nYjkcQyXZ0kgbIxrAwtHku2Y7o4kBa8SYow6omYvOqYnTfQZm4RQMZnMfmZb0VK5FZlozmrajY7d0EoAdyPHe08rmuG/eHNI6EFT15jEREQEREBERAREQEREBERAREQEREBERAREQEX4TsNz3KgbmrmdsMZh42tx7ZbNa1fnDo3xvjHKOxY5m0n4TfyiQ3aM7c24QS85qOrg4JuZst26yEzx42k0SWp2hzW+RHvuRzOaC47NHMC4gdV6JMXk8nkJzeutr46KzDNTgx7nxyuDBu4Tyb+U1zz+I0AbMAcXBzmiTh8BWw8cThzW77a8dWXJWg11qwxhcW9o8Ab+U97ths0F7tgN1ZoPRTpV8dWZXqV4qtdm/LFCwMa3c7nYDp1JJ/eveiICIiAvmX2fHDLW3FLg++lpjJYrH4TGtny2bbfmljlnjgj542R8kbg7ueSHEDcM/d9NLE8b5o6/BjXskpaI24C+TzkgH/AEd/Tcdf7uqDn3sN+GeueEPCSDS+s7+JyUNaTtcXNjLEshZBIOYxvD4mbcriSNt/xj3bBd3UXFV3VMXTgeNnxQsY4fpDQFKQEREBERBAyOCpZW1Rs2YS6xSm7evKx7mOY7YtPVpG4IcQWncHfqCqmtPmtNwVIMgZdQVWMsPs5WKJrJ4w3yoga8Y/CEt3aTGAS4N2Zs48ulRBFxeTq5rHVb9KZtipZjbNFK3fZzHDcHr17j51KVFmdMe2p7mSxVkYrPy1RVZfLDLHytfzsEkPMGyAEuHmcA94a5vMSvZHqSOvkHU8pG3FSSWm1aMliePkyDjEZPwPlblwDJN2EBw7Nx2LdnELlERAREQEREBERAREQEREBERAREQF4TTMrxPlle2ONjS5z3HYNA6kkrzWe1JBLk8xhMcat51EyuuT26tjso2GEtMccu3lOa9zgeUbA9mQ7du7SHhFUdrKKG3cDm4OQVblOlJBNWs87SZOacOLSASYtoXMaWmM8+/NyM0iIgIiICIiAiIgLn/E5x1RfwuiK/luyM7LuTLT/Q4+CRr382x/7V4ZCB5w+Qj8Q7aTVuq6+k8fDK+J9y9bmFWhj4f6W5YcCWxs/c1znOPRjGPe4hrXERdEaWs4KG5fy1hl3UWUkbPkLMW/ZtIbyshhB6thjHRo6bkveRzyPJDTIiICIiAiIgIiIC9c9eKywMmjZKwOa8Ne0OAc0hzT184IBB8xAK9iIM5Xsv0gyCrkbrpsSG8rMvkrMYe2V8wbFA87N5t+0YxjurnFuzyXkF+jXqs1obtaWvYiZPBKwxyRStDmvaRsWkHoQR02VNpy/PHcvYa9Ys3b1Lab25NUELJoZHPMfKW+Q4tDSx22x3aCWtDm7hfIiICIiAiIgIipcxrbT2n7QrZPOY7H2SObsbNpjH7fDyk77LOmiqubUxeVtddIst7qWjvSnEeux/WnupaO9KcR67H9a29XxtifSVyZ1NSiy3upaO9KcR67H9ae6lo70pxHrsf1p1fG2J9JMmdTUost7qWjvSnEeux/WnupaO9KcR67H9adXxtifSTJnU1KxHEHUWB0Xm9L5zP2oMZX7efHjJXMjHUr1+0hdKe0D3ND+Y12tAG5BIPduVO91LR3pTiPXY/rXwX/ANIHwPwvEHUtDiBofLY7JZe7JDRzFGtbY+R+wDIrIG/c1oax3wANPmcU6vjbE+kmTOp/Q3A6gxeqcTXymFyVPL4ywCYbtCdk8MoBLTyvaSDsQR0PeCrBc04c5/QfDrQWn9MUtUYYVsTRiptLbkY5yxoBd397juf3rRe6lo70pxHrsf1p1fG2J9JMmdTUost7qWjvSnEeux/WnupaO9KcR67H9adXxtifSTJnU1KLLe6lo70pxHrsf1p7qWjvSnEeux/WnV8bYn0kyZ1NSqfVGp6uk8YLViOe1NLIIKtGowPsW5nA8sUTSQC47EkkhrWtc97msa5wzmoeNekMFiZrcWZp5SduzIqdK1G6WZ7js1o3cGtG5G7nENaNy4gAlVOmNU6XivnP6g1bgrupJozG3sbsboMdC7lLq1YnY8pLGl8jgHSuaCQ1rY443V8bYn0kyZ1NPpjS9tmTfqLULoLGo5oTXY2s5z6+PrlwcYIC4AnctYZJS1rpXMaSGtZHHHqllvdS0d6U4j12P617IeJmkbEgZHqbEPcdgALsfnOw8/wkD96dXxtifSUtOppURFzoIiICIiAiIgIiICz2eJp6n03cHhiYSyT490NHZ1Rgkj7XtrLfMGmsGNeOrXTbdz3baFZ3WjfwGHfyZd5ZlKp2w52d1fy7zfDAN93/ANkfoQaJERAREQEREELNXHY/D3rTAC+CCSVoPwtaSP8AJZHSVSOtgKUgHNPZiZPPM7q+aRzQXPcT1JJP7u7uC0+qvexmPkc30Cs9pr3uYr5JF9AL0MDswp8V0LJERZoIiICIiAiIgIiICIiAiIgIiIC/HsbIwte0OaRsWuG4K/UQROHbxBDnMZGSKmMyJrVo9ukUboIZgxv9lplIA7gAAAAAFrljuH35T1n+2GfwNRbFc3Se9ny4xCznERFyoIiICIiAiIgLN655PaWK535dg8K09vA345PbN2Ev/kf+J/Y3WkWd1s4tp4vYZg75SmP9S/j/ANM3+l/8j/xP7HMg0SIiAiIgIiIKvVXvYzHyOb6BWe0173MV8ki+gFodVe9jMfI5voFZ7TXvcxXySL6AXo4Pcz4/C6FkiIskEREBERByT2SWtdVaI0zpuxpSGCS1c1HjaM/b2RDzRyWGN7Lcxv2EhPIXAbtDiRuRsvZnOL+pKeocdpTEaLgzWsXYsZbJUm5gQ1KMJeY2j2w6HeRznNcGjs29GknlCuuNegclxE0ZFTwtqrUzVDJU8tRfeDjXdNXnZK1knL5Qa7lIJAJG++x7lk7+hOJFXWFXXWHGlm6muYnwRl8XbsWfaJbHO+SCWGZsXOXNEjg5rmAHfoRtusJvceFL2SUmrK+mqej9KzZrU2XrWrc+Ku3W02Y2OtN2E/by8r+om/BtDWnm236BVNji7a11qbhLPTF/T8z9UZHEZvDmwfIngp2eeGQsPLK0Pa17T3HyTsD3eGnPY/ar4Yzacz+lcnh8tquCneqZluZ7WvVve2rPtp743Rte6Msl3DQWndp2Ox6r20/Y/anw2M01lamXxVvWVPVVrVGRNhkkdKw+1HJFNFHtu9obHIAwkHcs6gb9Mf3aRreF/GTJ8T9RZiKrpeOpp7HXbWPdkX5WN1ps0MhYRLV5A6LmIJb5RO2xIG4XU1xTE8J9W2uOlHW+Vj0ziK9FtyGSfAduLeXhkHLBHba5ob+DGzt+Z/lN6co6Ltazi+kERFkCIiAiIgg8PvynrP8AbDP4Gotisdw+/Kes/wBsM/gai2K5uld55R7QsiIi5UEREBEWR1lxNxWj5Parmy5DJlocKVUAuaD3F7js1g/Wdz12B2W3Cwq8arIw4vI1yLiVjjfqKZxdBicZVae5ks0kxH6yA3/Jen3adVfE8P8A7sv2l60fR+lzoj1hfN3NfH/svvZjZPgFrfHact6HuXMfIa2VpZehn/ahtiN4L4Xs9rP2bzNLXM5jzNIPTmXTfdp1V8Tw/wDuy/aXLuO+APshcfgampqGNaMPfbdhlrCQPc3p2kJJJ8h4Dd9uvkt2PRX9G6Xqj1g830lwe11kOJnDLT+qsngXaat5av7a8GOs+2DFG5x7M8/IzfmZyP8AxRtzbddt1slwmHjHqevEyKLH4WKJjQ1jGMlDWgdAAOboF5+7Tqr4nh/92X7Sfo3S9UesHm7mi4YONOqt+tLDkf8Apl+0rbEcdZ45WtzWFDIPPZx0plLevnjcAdh3+SSf0fDhX9I6XTF8m/hMFnXUUTFZWnm8fDeoWGWqkw3ZLGdweuxH6CCCCD1BBB6hS148xNM2nOir1V72Mx8jm+gVntNe9zFfJIvoBaHVXvYzHyOb6BWe0173MV8ki+gF6GD3M+PwuhZIvReqm7RsVxNJXM0boxNC7lezcbczT5iO8FV3ixB8cyXr0v2lZmUXCKn8WIPjmS9el+0nixB8cyXr0v2lLzqFwip/FiD45kvXpftJ4sQfHMl69L9pLzqFwip/FiD45kvXpftJ4sQfHMl69L9pLzqFwip/FiD45kvXpftJ4sQfHMl69L9pLzqFwip/FiD45kvXpftJ4sQfHMl69L9pLzqFwip/FiD45kvXpftJ4sQfHMl69L9pLzqFwip/FiD45kvXpftJ4sQfHMl69L9pLzqFwij0aLMfCYmSTSgnm5p5XSO/vcSVIVEHh9+U9Z/thn8DUWxWO4fflPWf7YZ/A1FsVz9K7zyj2hZERFyoIiIMrxI1c7R2mnWa4a7IWJG1qjX93aOBPMfhDWtc7bz8u3nXAgHFz3ySPnmkcXyTSu5nyOPe5x85XROPUr/DWlod/wACYrkpHm5x2Ab/AIPeueL7z6Pg04fRoxIz1X4Tb4JzCIi9xgIuAZeTWfEHXes62Lnnrx4SyylVjg1BJjuw3ha8SviZBIJeYuJBedthsB0JNlSxGoNUa9v4XP6iydOxU0zQmnZhbz68Ptwuna+VvLse9vd0B6cwOw24o6TebU0znt78ldtVdgtRY/U1WexjbHtmGCzLUkdyOZyyxvLJG7OA7nAjfuPm3XDtG6jzPFabQuGyWcv4yvLpkZi3LjLBrT3p+1EWxkbsQ0bFxDdty8b9FtPY91TR0XlKxmlsmHPZOPtp3c0km1p45nHzk7bk/CmH0j7tcRTHZMcuY6ciIu1F/oHVcmjNRROLyMVflbFciJ8lrj5LJgPM4Hla4+dvfvyN2+h18mZsA4a9v3dg/qR3eSV9UYmaSxi6csw2lfCxzwf+8WjdfH/XMGmmqjGjPN4nysz0I2qvexmPkc30Cs9pr3uYr5JF9ALQ6q97GY+RzfQKz2mve5ivkkX0AvIwe5nx+F0LJERZIIsnxX1q/hxw21JqeOq+5Ji6MllsUbWuJIHQlrnsDgO8gOBIBDd3EA5LO+yCpaO8I18tgc1cnwdenJm7mNrRe1aZnYCHeXMHEAnq1oc8DrsR1WMzEDrKLmFLjFYPEPXOLyGEnx+ldLwROs5+SSDso5OwNiUyfhufl7J0Jbyxk9Xc3L03r5/ZN4Cjjspdv4HUOOip4nw3AyzWhEt6qZGxtdEwSlzXOc9gDJRG4793Q7MqB19FzzK8Y2Ye7gsfPpHUTsvm32RRxsbKpmeyBjHukce35I2kPaBzuaQTs4NJC/ZeNuGgwOXyslDJNjxuch08+ARxmWa3JJBEBHtJs5ofYDSSR1Y/YHYbrwOhIuYQeyAxE2XgrPwWdgxs2cl06zNSQQ+0zdZM+Hk6SmTldIwtD+Tl3IBIO4EvhDxLyvEluoLNzTdrD46plLNOhblkgcyzHDKYX/iTPdziSOXc8obty8pd1KXgdERZefilourqAYKbV+BizhmbWGMkycLbJlcQGx9kXc3MSQA3bc7hZ/jfrjK6Kx2lW4WOzPkMrqGnR9r04o5Jp4RzTTxsEmzQXRQyN5iW8vNvzN23FvA6Qi5fD7ITBW6NIVMTmreftXbOPbpuOCIX2TV9jOH80gia1gcwl5k5CHs2ceYLN6l415HWfue0NF1cxSZqqe1JPkIIqTrNSvW5mzBjZ5DHziXswXbPbyFxbzktCmVA7oi5tiuOeFyOZxVKLH5d2Lyd6TF0NRyQxCjctRtkLmMIf2nXspAHmMMcW+S47jeJjfZEYTI6Rg1N4DztbD3ZWVsZJNBCZMnO+R0bIq8TZS8ucWkguDW8vlc2wJDKgdURZbQHECrxAqZWSHHXsTaxd52Ou0sh2RlhmbHHIRvFJIxw5ZWHdrj3kHYghalUQeH35T1n+2GfwNRbFY7h9+U9Z/thn8DUWxXP0rvPKPaFkREXKgiIgwHGXTU2a05BeqROmt4ub2x2bBu6SItLZGj9xD9vOWAedcXY9srGvY4PY4bhzTuCPhC+p1ynWvB2WazLf02+vC6Q80mNn8iJzvO6NwB5CevkkEE+dvUn6f6V9QowafsY02jRPwZ3z/LQ1+ZXmPO6bbHueUPwtgkDzbn22Nz+5fj6HEEuPLndNBu/QHC2CQPW10KxpTU1NxbPpnJNcO/smsmH7ixxXp8A570by/qp+tfSxVgT2xif8v8AtMmXPsvwj07q2eHIajxsF3Mmu2C1ZpPmqssAd4cxsnlM79mvLth03Wir6YxlTN2MvDVDMjYrR05Zg93lRRlxY3l32Gxe7qBv1/Ur/wAA570by/qp+tPAOe9G8v6qfrWcVdHibxNN/GDJlgbfBzSF3DYbFy4jarhmllAxWZo5a7T3hsrXh+x84Luu3VflfROQ0hRix2iJsRhMWHyTSV8hTntkyvcXOc1wsM2BJ7uv6Nu5b/wDnvRvL+qn608A570by/qp+tY/42eJpid0xBkywPg/iH+ftM//AISx97V1pyvqKA2PD1/GXgeXsfB1GSty9/Nzc80nNv022222Pfv00gwOfP8A8N5f1U/WrbEcNtVZuVrfBgxEJ77OQe07dfNGxxcT+g8v61jOL0fC/dViR+V+FzJlUYfASatzdPCxNLm2Hc1lzTt2dcdZHH9fRg/S8L6bAAAAGwHmWf0ZoihoqhJFV5p7U5DrNyX+kmI32H6Gjc7NHQbk9SXE6FfF/Uumx0zEjI/1pzfMstyr1V72Mx8jm+gVntNe9zFfJIvoBaHVXvYzHyOb6BWe0173MV8ki+gFpwe5nx+DQl3rElSlYnirS3ZYo3PZWgLBJKQNwxpe5rQT3DmcBuepA6rI+P8Anf8A5a6o9ZxX31bVFUc11Xj8lxg0zf0vd09mdI1bJgklvZD2lPHIyOxE98IbBae7eRjXN3I2AJPUgNPoz3BHw/jtaVZs1yu1RnKeUsS+1dzHXriq32qBz9Q5tYjn83ak8p269RRS2scptcDpslV4l4m9n2z6d1q6aaSuylyW6k0kEUJcJ+0LXta2JvK0xjbzkgKFjPY9x1NFyYCSfT9Iz5ShetT6f04zGttRVrEc3ZSMbK7dzzGQX77AOOzPMuxomTAzFnRPtviXj9WyXOYUcTYxkFIxfimaaKSSXn5u8iBjduX4evmXPvcGyda9XMuq2S6dqapm1Z4OjxJNmeR0sk4hfN2x5g2R7S0tjB2YAQehHaES0DgXBzhFqHI6O0Rb1flRHSqT+MTNOtxhrTxX5nyT7WpXSOLzHJO88oZH5QHNvyro3CPQGR4Z6XOBt5uHN04JpX05G0TXlYx8j5CJT2jxI/med3gM3/7q26JERAy8/DnFWNQDMvt54WxM2fs49Q5BlbmaQQPa4nEXL06s5OU9dwdyqviPw8y+r8/pbM4fP1sLc0/JYnhZbxxuRSSyxdiHOaJYz5Mb5gAD3vB32aQ7eIraBwTLexQoXXYq8Mjjsrm4JLs2Qs6nwkeTr35bT43yyGDnjEbmmJgYWu8lo5SHAla3GaRvScbKuT8HClp7TunXYmlIGMjjlnnliklMMbT5LGMgibvsBu4gb7FdORTJgcZ017H29hMXgcTZ1WLmI0xHP4v12Y7sn15XxSRRzWH9qe3fGyV4byiMEuJIJ2Il6o9j3Q1Dwq0Xo1tqofFU1H1Jcjjm3Ks7oYHQHtq7nAPa5kj9xzggkEO3C62iZMCj0TpeHRumKOJhgx0AgaeZuJoNpVuYkklkLS4MHXu3J+ElXiIqIPD78p6z/bDP4Gotisdw+/Kes/2wz+BqLYrn6V3nlHtCyIiLlQREQEREBERAREQEREBERAREQV2o4X2NPZSKNpdI+rK1rR5yWEBZrS72yaaxLmndrqkJB+EcgW2WTtcPm9vI/GZvJYOF7i81aYgfCHHqS1ssT+Xc9dmkDck7dV24OJTFM0VTbSuiySigeIGQ9M838xS+7p4gZD0zzfzFL7ut98PbjjyLb09FA8QMh6Z5v5il93TxAyHpnm/mKX3dL4e3HHkW3p6KB4gZD0zzfzFL7uniBkPTPN/MUvu6Xw9uOPItvT0UDxAyHpnm/mKX3dPEDIemeb+Ypfd0vh7cceRbenooHiBkPTPN/MUvu6eIGQ9M838xS+7pfD2448i29PRQPEDIemeb+Ypfd08QMh6Z5v5il93S+Htxx5Ft6eigeIGQ9M838xS+7p4gZD0zzfzFL7ul8PbjjyLb09FA8QMh6Z5v5il93TxAyHpnm/mKX3dL4e3HHkW3p6KB4gZD0zzfzFL7uvJmgbm5Eurs1Mw97ezqM36/C2AEfuPnUvh7cceRbe/eH7CL2rZQd2S5cFp2PmqVmH/9muH7lr1ExWKq4THw0qUIgrRAhrdy4kkklxJ3LnEkkuJJJJJJJKlrixq4xK5qjNy7Ce0REWlBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERAREQf/2Q==\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Inspect the current state as before to confirm the checkpoint reflects our manual updates."],"metadata":{"id":"fexYIigbGKau"}},{"cell_type":"code","source":["snapshot = graph.get_state(config)\n","print(snapshot.values[\"messages\"][-3:])\n","print(snapshot.next)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xF2UTA2YGL4x","executionInfo":{"status":"ok","timestamp":1726072754339,"user_tz":420,"elapsed":32,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"763092f5-a2e1-480a-9d05-ee018152dc43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ToolMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='7a6e8c97-dba3-428e-8347-6e57651a11dc', tool_call_id='chatcmpl-tool-7766e89b71d042eb880822c7542f8ad1'), AIMessage(content='LangGraph is a library for building stateful, multi-actor applications with LLMs.', id='29d7b79b-db9b-42c3-9d38-ab2147c171e3'), AIMessage(content=\"I'm an AI expert!\", id='b2021974-0331-4a90-8d41-b25227e3b00e')]\n","()\n"]}]},{"cell_type":"markdown","source":["As an example, let's update the tool invocation to make sure we get good results from our search engine! First, start a new thread:"],"metadata":{"id":"45e_GCy6GQjo"}},{"cell_type":"code","source":["user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n","config = {\"configurable\": {\"thread_id\": \"2\"}}  # we'll use thread_id = 2 here\n","events = graph.stream(\n","    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",")\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYvEQJe1GRrG","executionInfo":{"status":"ok","timestamp":1726072770431,"user_tz":420,"elapsed":9955,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"c3ec8a44-4d10-47c9-beb6-bfb4c0bb4570"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","I'm learning LangGraph. Could you do some research on it for me?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  tavily_search_results_json (chatcmpl-tool-0f91d6404e804ac6884bbadd93c5776d)\n"," Call ID: chatcmpl-tool-0f91d6404e804ac6884bbadd93c5776d\n","  Args:\n","    query: LangGraph\n"]}]},{"cell_type":"markdown","source":["Next, let's update the tool invocation for our agent. Maybe we want to search for human-in-the-loop workflows in particular."],"metadata":{"id":"mdcwlglpGUGm"}},{"cell_type":"code","source":["from langchain_core.messages import AIMessage\n","\n","snapshot = graph.get_state(config)\n","existing_message = snapshot.values[\"messages\"][-1]\n","print(\"Original\")\n","print(\"Message ID\", existing_message.id)\n","print(existing_message.tool_calls[0])\n","new_tool_call = existing_message.tool_calls[0].copy()\n","new_tool_call[\"args\"][\"query\"] = \"LangGraph human-in-the-loop workflow\"\n","new_message = AIMessage(\n","    content=existing_message.content,\n","    tool_calls=[new_tool_call],\n","    # Important! The ID is how LangGraph knows to REPLACE the message in the state rather than APPEND this messages\n","    id=existing_message.id,\n",")\n","\n","print(\"Updated\")\n","print(new_message.tool_calls[0])\n","print(\"Message ID\", new_message.id)\n","graph.update_state(config, {\"messages\": [new_message]})\n","\n","print(\"\\n\\nTool calls\")\n","graph.get_state(config).values[\"messages\"][-1].tool_calls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ex4YGf0hGVM5","executionInfo":{"status":"ok","timestamp":1726072772725,"user_tz":420,"elapsed":89,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"3f0d3586-d16d-46d6-9072-a04fe7adc970"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original\n","Message ID run-7cb1d704-1961-4b31-9f5b-196c40e333ef-0\n","{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph'}, 'id': 'chatcmpl-tool-0f91d6404e804ac6884bbadd93c5776d', 'type': 'tool_call'}\n","Updated\n","{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph human-in-the-loop workflow'}, 'id': 'chatcmpl-tool-0f91d6404e804ac6884bbadd93c5776d', 'type': 'tool_call'}\n","Message ID run-7cb1d704-1961-4b31-9f5b-196c40e333ef-0\n","\n","\n","Tool calls\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'name': 'tavily_search_results_json',\n","  'args': {'query': 'LangGraph human-in-the-loop workflow'},\n","  'id': 'chatcmpl-tool-0f91d6404e804ac6884bbadd93c5776d',\n","  'type': 'tool_call'}]"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["Notice that we've modified the AI's tool invocation to search for \"LangGraph human-in-the-loop workflow\" instead of the simple \"LangGraph\"."],"metadata":{"id":"lMW74ZPbGYbe"}},{"cell_type":"markdown","source":["Resume the graph by streaming with an input of None and the existing config."],"metadata":{"id":"_yIoUgFAGacU"}},{"cell_type":"code","source":["events = graph.stream(None, config, stream_mode=\"values\")\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8t2OwTStGbro","executionInfo":{"status":"ok","timestamp":1726072796998,"user_tz":420,"elapsed":14818,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"2c91019f-6af3-4a20-d06a-a76f1242a956"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==================================\u001b[1m Ai Message \u001b[0m==================================\n","Tool Calls:\n","  tavily_search_results_json (chatcmpl-tool-0f91d6404e804ac6884bbadd93c5776d)\n"," Call ID: chatcmpl-tool-0f91d6404e804ac6884bbadd93c5776d\n","  Args:\n","    query: LangGraph human-in-the-loop workflow\n","=================================\u001b[1m Tool Message \u001b[0m=================================\n","Name: tavily_search_results_json\n","\n","[{\"url\": \"https://www.geeky-gadgets.com/human-in-the-loop-ai/\", \"content\": \"Human in the Loop AI systems with LangChain and LangGraph.js By integrating human intervention at key decision points, such as processing refunds, LangGraph.js addresses the problem of potential AI errors or misuse. HITL involves strategically integrating human intervention and decision-making into AI workflows, allowing for a seamless collaboration between human expertise and machine intelligence. This guide by the team at LangChain explores the significance of HITL and how LangGraph.js, a powerful tool for AI workflow management, assists its implementation. By using LangSmith\\u2019s logging capabilities, you can maintain a high level of control over the AI workflow and ensure that human interventions are correctly integrated and effective. With its support for interrupts, checkpoints, and dynamic interrupts, LangGraph.js enables seamless collaboration between human experts and AI systems.\"}, {\"url\": \"https://www.youtube.com/watch?v=9BPCV5TYPmg\", \"content\": \"In this video, I'll show you how to handle persistence with LangGraph, enabling a unique Human-in-the-Loop workflow. This approach allows a human to grant an...\"}]\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","Based on the search results, it appears that LangGraph is a tool for AI workflow management that allows for human intervention at key decision points. This is known as Human-in-the-Loop (HITL) AI. LangGraph.js is a JavaScript library that provides a powerful tool for implementing HITL AI systems.\n","\n","The first search result from Geeky Gadgets provides an overview of HITL AI and how LangGraph.js can be used to implement it. It highlights the importance of integrating human expertise and machine intelligence to ensure that AI systems are accurate and trustworthy.\n","\n","The second search result is a YouTube video that demonstrates how to handle persistence with LangGraph, enabling a unique Human-in-the-Loop workflow. This approach allows a human to grant an AI system the ability to make decisions, but also allows the human to intervene and correct any errors or biases.\n","\n","Overall, it seems that LangGraph is a powerful tool for implementing HITL AI systems, allowing for seamless collaboration between human experts and AI systems.\n"]}]},{"cell_type":"code","source":["events = graph.stream(\n","    {\n","        \"messages\": (\n","            \"user\",\n","            \"Remember what I'm learning about?\",\n","        )\n","    },\n","    config,\n","    stream_mode=\"values\",\n",")\n","for event in events:\n","    if \"messages\" in event:\n","        event[\"messages\"][-1].pretty_print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaOMkvsNHfI4","executionInfo":{"status":"ok","timestamp":1726072851663,"user_tz":420,"elapsed":4735,"user":{"displayName":"Kaikai Liu","userId":"13976416703683897255"}},"outputId":"24b7fc12-51bc-4379-a37c-d8ddfdabdd4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["================================\u001b[1m Human Message \u001b[0m=================================\n","\n","Remember what I'm learning about?\n","==================================\u001b[1m Ai Message \u001b[0m==================================\n","\n","You're learning about LangGraph. I did some research on it for you earlier.\n"]}]}]}